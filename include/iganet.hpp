#include <array>
#include <vector>

#include <torch/torch.h>
#include <matplot/matplot.h>

#include <core.hpp>
#include <bspline.hpp>

#pragma once

namespace iganet {

  /**
   * IgANetGeneratorImpl
   *
   * @note Following the discussion of module overship here
   *
   * https://pytorch.org/tutorials/advanced/cpp_frontend.html#module-ownership
   * 
   * we implement a generator implementation class following
   *
   * https://pytorch.org/tutorials/advanced/cpp_frontend.html#the-generator-module
   */
  template<typename real_t>
  class IgANetGeneratorImpl :
    public torch::nn::Module
  {
  public:
    // Constructor
    IgANetGeneratorImpl(const std::vector<int64_t>& layers)
    {
      // Generate vector of linear layers and register them as fcX
      for (auto i=0; i<layers.size()-1; ++i)
        {
          fc.emplace_back(register_module("fc" + std::to_string(i),
                                          torch::nn::Linear(layers[i], layers[i+1])));
        }
    }

    // Forward evaluation
    torch::Tensor forward(torch::Tensor x)
    {
      // Standard feed-forward neural network with ReLU activation functions
      for (auto it=fc.begin(); it!=fc.end()-1; ++it)
        x = torch::relu(it->forward(x));
      x = fc.end()->forward(x);
      return x;
    }
    
  private:
    // Vector of linear layers
    std::vector<torch::nn::Linear> fc;
  };

  /**
   * IgANetGenerator
   *
   * @note: This class is normally generated by the TORCH_MODULE
   * macro. Since the latter cannot handle templated classes
   * correctly, we give the implementation explicitly
   */
  template<typename real_t>
  class IgANetGenerator :
    public torch::nn::ModuleHolder<IgANetGeneratorImpl<real_t>> {

  public:
    using torch::nn::ModuleHolder<IgANetGeneratorImpl<real_t>>::ModuleHolder;
    using Impl = IgANetGeneratorImpl<real_t>;
  };
  
  template<typename real_t, short_t... Degrees>
  class IgANet : public core<real_t>
  {
  private:
    // Dimension of the differential equation
    static constexpr const short_t dim_ = sizeof...(Degrees);
    
    // B-spline representation of the geometry
    BSpline<real_t, dim_, Degrees...> geo_;

    // B-spline representation of the right-hand side
    BSpline<real_t, 1, Degrees...> rhs_;

    // B-spline representation of the solution
    BSpline<real_t, 1, Degrees...> sol_;

    // Input tensor
    torch::Tensor input_;
    
    // Tensor servering as global input
    torch::Tensor input__;
    
    // IgANet generator
    IgANetGenerator<real_t> net_;

  public:
    // Constructor: layers + bspline (same for all)
    IgANet(const std::vector<int64_t>& layers,
           const std::array<int64_t,dim_>& bspline)
      : IgANet(layers, bspline, bspline, bspline)
    {    
    }

    // Constructor: layers + geo_bspline + rhs_bspline
    IgANet(const std::vector<int64_t>& layers,
           const std::array<int64_t,dim_>& geo_bspline,
           const std::array<int64_t,dim_>& rhs_bspline,
           const std::array<int64_t,dim_>& sol_bspline)
      : core<real_t>(),
        
        /* Construct the different BSpline objects individually */
        geo_(geo_bspline, BSplineInit::linear),
        rhs_(rhs_bspline, BSplineInit::ones),
        sol_(sol_bspline, BSplineInit::random),
        
        /* Construct one large tensor comprising all BSpline object's
           coefficient vectors - we need this complicated construction
           to first concatenate the multiple std::array<torch::Tensor,*>
           objects into a single std::array<torch::Tensor,*> object and
           then initialize a new large torch::Tensor with its data */
        input__(torch::concat(
                              concat(geo_.coeffs(),
                                     rhs_.coeffs(),
                                     std::array<torch::Tensor,1>({torch::ones({dim_}, core<real_t>::options_)}))
                              )
                ),
        
        /* Construct the deep neural network with the large tensor as
           input and the coefficient vector of the solution's BSpline
           object as output */
        net_(concat(std::vector<int64_t>{static_cast<int64_t>(input__.size(0))},
                    layers,
                    std::vector<int64_t>{sol_.ncoeffs()}))
    {
      // Now that everything is in placed we swap the coefficient
      // vectors of the BSpline objects with views on parts of the one
      // large tensor
      int64_t count = 0;
      
      // Geometry
      for (short_t i=0; i<dim_; ++i)
        {
          geo_.coeffs(i) = input__.index({torch::indexing::Slice(count,
                                                                 count+=geo_.ncoeffs(),
                                                                 1)});
        }
      
      // Right-hand side
      rhs_.coeffs(0) = input__.index({torch::indexing::Slice(count,
                                                             count+=rhs_.ncoeffs(),
                                                             1)});
      
      // Input tensor
      input_ = input__.index({torch::indexing::Slice(count,
                                                     count+=dim_,
                                                     1)});
    }

    // Returns a constant reference to the B-spline representation of the geometry
    inline const BSpline<real_t, dim_, Degrees...>& geo() const
    {
      return geo_;
    }

    // Returns a non-constant reference to the B-spline representation of the geometry
    inline BSpline<real_t, dim_, Degrees...>& geo()
    {
      return geo_;
    }

    // Returns a constant reference to the B-spline representation of the right-hand side
    inline const BSpline<real_t, 1, Degrees...>& rhs() const
    {
      return rhs_;
    }
    
    // Returns a non-constant reference to the B-spline representation of the right-hand side
    inline BSpline<real_t, 1, Degrees...>& rhs()
    {
      return rhs_;
    }

    // Returns a constant reference to the B-spline representation of the solution
    inline const BSpline<real_t, 1, Degrees...>& sol() const
    {
      return sol_;
    }

    // Returns a non-constant reference to the B-spline representation of the solution
    inline BSpline<real_t, 1, Degrees...>& sol()
    {
      return sol_;
    }

    // Returns a constant reference to the input tensor
    inline const torch::Tensor* input() const
    {
      return input_;
    }

    // Returns a non-constant reference to the input tensor
    inline torch::Tensor* input()
    {
      return input_;
    }

    // Returns the dimension
    inline constexpr short_t dim() const
    {
      return dim_;
    }
    
    // Returns a string representation of the IgANet object
    inline void pretty_print(std::ostream& os = std::cout) const
    {
      os << "=== IgANet ===\n"
         << "net = " << net_ << "\n"
         << "geo = " << geo_ << "\n"
         << "rhs = " << rhs_ << "\n"
         << "sol = " << sol_;
    }

    // Plots the B-Spline solution
    inline void plot(short_t nref=0) const
    {
      if constexpr(dim_==1) {
        assert(geo_.ncoeffs(0) == sol_.ncoeffs(0));
        
        auto x = geo_.template coeffs<false>(0);
        auto c = sol_.template coeffs<false>(0);
        
        matplot::vector_1d X(geo_.ncoeffs(0), 0.0);
        matplot::vector_1d C(geo_.ncoeffs(0), 0.0);
        
        for (int64_t i=0; i<geo_.ncoeffs(0); ++i) {
          X[i] = x[i].template item<real_t>();
          C[i] = c[i].template item<real_t>();
        }

        matplot::plot(X, C);
        matplot::show();

      }

      else if constexpr(dim_==2) {
        assert((geo_.ncoeffs(0) == sol_.ncoeffs(0)) && (geo_.ncoeffs(1) == sol_.ncoeffs(1)));

        auto x = geo_.template coeffs<false>(0);
        auto y = geo_.template coeffs<false>(1);
        auto c = sol_.template coeffs<false>(0);

        matplot::vector_2d X(geo_.ncoeffs(1), matplot::vector_1d(geo_.ncoeffs(0), 0.0));
        matplot::vector_2d Y(geo_.ncoeffs(1), matplot::vector_1d(geo_.ncoeffs(0), 0.0));
        matplot::vector_2d C(geo_.ncoeffs(1), matplot::vector_1d(geo_.ncoeffs(0), 0.0));
        matplot::vector_2d U(geo_.ncoeffs(1), matplot::vector_1d(geo_.ncoeffs(0), 0.0));

        // Convert into Matplot++ format
        for (int64_t i=0; i<geo_.ncoeffs(0); ++i)
         for (int64_t j=0; j<geo_.ncoeffs(1); ++j) {
           X[j][i] = x[i][j].template item<real_t>();
           Y[j][i] = y[i][j].template item<real_t>();
           C[j][i] = c[i][j].template item<real_t>();
           U[j][i] = sol_.eval(torch::stack(
                                            {
                                              torch::full({1}, X[j][i]),
                                              torch::full({1}, Y[j][i])
                                            }
                                            ).view({2})
                               ).template item<real_t>();
         }
        
        // Plot control net
        //matplot::mesh(X, Y, C)->palette_map_at_surface(true).face_alpha(0);
        //matplot::hold(matplot::on);

        // Plot solution
        matplot::surf(X, Y, U);
        //matplot::hold(matplot::off);
        
        matplot::show();
      }

      else if constexpr (dim_==3){        
      }

      else
        throw std::runtime_error("Unsupported dimension");
    }
  };

  /// Print (as string) a IgANet object
  template<typename real_t, short_t... Degrees>
  inline std::ostream& operator<<(std::ostream& os,
                                  const IgANet<real_t, Degrees...>& obj)
  {
    obj.pretty_print(os);
    return os;
  }
  
} // namespace iganet
